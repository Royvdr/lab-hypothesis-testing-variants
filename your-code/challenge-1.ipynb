{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - T-test\n",
    "\n",
    "In statistics, t-test is used to test if two data samples have a significant difference between their means. There are two types of t-test:\n",
    "\n",
    "* **Student's t-test** (a.k.a. independent or uncorrelated t-test). This type of t-test is to compare the samples of **two independent populations** (e.g. test scores of students in two different classes). `scipy` provides the [`ttest_ind`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) method to conduct student's t-test.\n",
    "\n",
    "* **Paired t-test** (a.k.a. dependent or correlated t-test). This type of t-test is to compare the samples of **the same population** (e.g. scores of different tests of students in the same class). `scipy` provides the [`ttest_re`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_rel.html) method to conduct paired t-test.\n",
    "\n",
    "Both types of t-tests return a number which is called the **p-value**. If p-value is below 0.05, we can confidently declare the null-hypothesis is rejected and the difference is significant. If p-value is between 0.05 and 0.1, we may also declare the null-hypothesis is rejected but we are not highly confident. If p-value is above 0.1 we do not reject the null-hypothesis.\n",
    "\n",
    "Read more about the t-test in [this article](http://b.link/test50) and [this Quora](http://b.link/unpaired97). Make sure you understand when to use which type of t-test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "\n",
    "In this challenge we will work on the Pokemon dataset. The goal is to test whether different groups of pokemon (e.g. Legendary vs Normal, Generation 1 vs 2, single-type vs dual-type) have different stats (e.g. HP, Attack, Defense, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load the dataset\n",
    "pokemon = pd.read_csv('Pokemon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to define a function with which we can test the means of a feature set of two samples. \n",
    "\n",
    "In the next cell you'll see the annotations of the Python function that explains what this function does and its arguments and returned value. This type of annotation is called **docstring** which is a convention used among Python developers. The docstring convention allows developers to write consistent tech documentations for their codes so that others can read. It also allows some websites to automatically parse the docstrings and display user-friendly documentations.\n",
    "\n",
    "Follow the specifications of the docstring and complete the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def t_test_features(s1, s2, features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    \"\"\"Test means of a feature set of two samples\n",
    "    \n",
    "    Args:\n",
    "        s1 (dataframe): sample 1\n",
    "        s2 (dataframe): sample 2\n",
    "        features (list): an array of features to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionary of t-test scores for each feature where the feature name is the key and the p-value is the value\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Loop through each feature in the list\n",
    "    for feature in features:\n",
    "        # Perform an independent t-test on the current feature\n",
    "        t_stat, p_val = ttest_ind(s1[feature], s2[feature])\n",
    "        \n",
    "        # Store the p-value in the dictionary with the feature name as the key\n",
    "        results[feature] = p_val\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `t_test_features` function, conduct t-test for Lengendary vs non-Legendary pokemons.\n",
    "\n",
    "*Hint: your output should look like below:*\n",
    "\n",
    "```\n",
    "{'HP': 1.0026911708035284e-13,\n",
    " 'Attack': 2.520372449236646e-16,\n",
    " 'Defense': 4.8269984949193316e-11,\n",
    " 'Sp. Atk': 1.5514614112239812e-21,\n",
    " 'Sp. Def': 2.2949327864052826e-15,\n",
    " 'Speed': 1.049016311882451e-18,\n",
    " 'Total': 9.357954335957446e-47}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': np.float64(3.3306476848461913e-15),\n",
       " 'Attack': np.float64(7.827253003205333e-24),\n",
       " 'Defense': np.float64(1.5842226094427259e-12),\n",
       " 'Sp. Atk': np.float64(6.314915770427265e-41),\n",
       " 'Sp. Def': np.float64(1.8439809580409597e-26),\n",
       " 'Speed': np.float64(2.3540754436898437e-21),\n",
       " 'Total': np.float64(3.0952457469652825e-52)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a dataframe for Legendary Pokémon (s1)\n",
    "legendary = pokemon[pokemon['Legendary'] == True]\n",
    "\n",
    "# 2. Create a dataframe for Non-Legendary Pokémon (s2)\n",
    "non_legendary = pokemon[pokemon['Legendary'] == False]\n",
    "\n",
    "# 3. Call the function using these two samples\n",
    "results = t_test_features(legendary, non_legendary)\n",
    "\n",
    "# Print the results to see the dictionary output\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the test results above, what conclusion can you make? Do Legendary and non-Legendary pokemons have significantly different stats on each feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dare to conclude that Legendary Pokemon actually are stronger significantly compared to non-Legendary on every single stat category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, conduct t-test for Generation 1 and Generation 2 pokemons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': np.float64(0.13791881412813622),\n",
       " 'Attack': np.float64(0.24050968418101454),\n",
       " 'Defense': np.float64(0.5407630349194362),\n",
       " 'Sp. Atk': np.float64(0.14119788176331508),\n",
       " 'Sp. Def': np.float64(0.16781226231606386),\n",
       " 'Speed': np.float64(0.00283569548125787),\n",
       " 'Total': np.float64(0.5599140649014442)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a dataframe for Generation 1 Pokémon (s1)\n",
    "gen1 = pokemon[pokemon['Generation'] == 1]\n",
    "\n",
    "# 2. Create a dataframe for Generation 2 Pokémon (s2)\n",
    "gen2 = pokemon[pokemon['Generation'] == 2]\n",
    "\n",
    "# 3. Call your function using these two samples\n",
    "results_gen = t_test_features(gen1, gen2)\n",
    "\n",
    "# Print the results to see the dictionary output\n",
    "results_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no significant difference between Gen 1 and Gen 2 Pokemon in the stat vatgeories. The only remarkable one is speed, which is below 0,05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare pokemons who have single type vs those having two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': np.float64(0.11060643144431842),\n",
       " 'Attack': np.float64(0.00015741395666164396),\n",
       " 'Defense': np.float64(3.250594205757004e-08),\n",
       " 'Sp. Atk': np.float64(0.0001454917404035147),\n",
       " 'Sp. Def': np.float64(0.00010893304795534394),\n",
       " 'Speed': np.float64(0.024051410794037463),\n",
       " 'Total': np.float64(1.1749035008828753e-07)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a dataframe for Single-Type Pokémon (Type 2 is null)\n",
    "single_type = pokemon[pokemon['Type 2'].isnull()]\n",
    "\n",
    "# 2. Create a dataframe for Two-Type Pokémon (Type 2 is not null)\n",
    "two_types = pokemon[pokemon['Type 2'].notnull()]\n",
    "\n",
    "# 3. Call your function using these two samples\n",
    "results_types = t_test_features(single_type, two_types)\n",
    "\n",
    "# Print the results to see the dictionary output\n",
    "results_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all stats except HP I reject the null hypothesis, since except HP all is less than 0,05.\n",
    "\n",
    "# Having a secondary type makes a statistically significant difference in almost every single battle stat (and their overall Total score). Dual-type Pokémon have distinct mathematical advantages over single-type Pokémon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we want to compare whether there are significant differences of `Attack` vs `Defense`  and  `Sp. Atk` vs `Sp. Def` of all pokemons. Please write your code below.\n",
    "\n",
    "*Hint: are you comparing different populations or the same population?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack vs Defense -- T-statistic: 4.3256, P-value: 1.7140303479358558e-05\n",
      "Sp. Atk vs Sp. Def -- T-statistic: 0.8540, P-value: 0.3933685997548122\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# 1. Paired T-test for Attack vs Defense because it is the same population.\n",
    "t_stat_ad, p_val_ad = ttest_rel(pokemon['Attack'], pokemon['Defense'])\n",
    "print(f\"Attack vs Defense -- T-statistic: {t_stat_ad:.4f}, P-value: {p_val_ad}\")\n",
    "\n",
    "# 2. Paired T-test for Sp. Atk vs Sp. Def because it is the same population\n",
    "t_stat_sp, p_val_sp = ttest_rel(pokemon['Sp. Atk'], pokemon['Sp. Def'])\n",
    "print(f\"Sp. Atk vs Sp. Def -- T-statistic: {t_stat_sp:.4f}, P-value: {p_val_sp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a statistically significant difference between the average Attack and average Defense of all Pokémon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to assume Special Attack and Special Defense are essentially equal across the population."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
